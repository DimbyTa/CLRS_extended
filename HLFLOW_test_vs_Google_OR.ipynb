{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport networkx as nx\nimport random\nfrom ortools.graph.python import max_flow\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport sys\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-18T01:43:51.676403Z","iopub.execute_input":"2023-05-18T01:43:51.676918Z","iopub.status.idle":"2023-05-18T01:43:51.908166Z","shell.execute_reply.started":"2023-05-18T01:43:51.676877Z","shell.execute_reply":"2023-05-18T01:43:51.906752Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## **Génération de réseaux et test de l'implémentation de l'algorithme Push-Relabel de Goldberg Tarjan**:\n### Variante de l'étiquette la plus élevée","metadata":{}},{"cell_type":"markdown","source":"Afin de vérifier l'exactitude de l'implémentation de l'algorithme Push-Relabel de Goldberg Tarjan (1988), nous la comparerons avec l'implémentation de l'outil Google OR-Tools (https://developers.google.com/optimization?hl=fr) du même algorithme.","metadata":{}},{"cell_type":"code","source":"random.seed(42)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T01:43:51.911572Z","iopub.execute_input":"2023-05-18T01:43:51.912350Z","iopub.status.idle":"2023-05-18T01:43:51.918700Z","shell.execute_reply.started":"2023-05-18T01:43:51.912295Z","shell.execute_reply":"2023-05-18T01:43:51.917375Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"#### Génération de réseaux","metadata":{}},{"cell_type":"code","source":"def add_capacity(Network, minimum_capacity, maximum_capacity):\n    \"\"\"\n    Network: Networkx object of class Digraph\n    minimum_capacity: the min of the capacity of an edge\n    maximum_capacity: the max of the capacity of an edge\n    \"\"\"\n    network = Network.copy()\n    for u,v,capacity in network.edges(data=\"capacity\"):\n        if capacity is None:\n            network.edges[u,v][\"capacity\"] = random.randint(minimum_capacity,maximum_capacity)\n    return network","metadata":{"execution":{"iopub.status.busy":"2023-05-18T01:43:51.920813Z","iopub.execute_input":"2023-05-18T01:43:51.921396Z","iopub.status.idle":"2023-05-18T01:43:51.939078Z","shell.execute_reply.started":"2023-05-18T01:43:51.921346Z","shell.execute_reply":"2023-05-18T01:43:51.937729Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def generate_networks(number_of_networks, number_of_nodes, minimum_capacity, maximum_capacity, probability_of_link):\n    \"\"\"\n    returns a list of size number_of_networks of adjacency matrices of size number_of_nodes x number_of_nodes\n    minimum_capacity: the min of the capacity of an edge\n    maximum_capacity: the max of the capacity of an edge\n    probability_of_link: the probability of a link being present in the network\n    \"\"\"\n    #list_of_seed = list(np.random.randint(30,high=100,size=number_of_networks))\n    list_of_adj = []\n    \n    for _ in range(number_of_networks):\n        #print(s)\n        random_network = nx.gnp_random_graph(number_of_nodes, probability_of_link, seed = None, directed = True)\n        #print(random_network.edges())\n        random_network = add_capacity(random_network, minimum_capacity, maximum_capacity)\n        #nx.draw(random_network)\n        #plt.show()\n        list_of_adj.append(nx.adjacency_matrix(random_network, weight = 'capacity').toarray())\n    return list_of_adj","metadata":{"execution":{"iopub.status.busy":"2023-05-18T01:43:51.941515Z","iopub.execute_input":"2023-05-18T01:43:51.942278Z","iopub.status.idle":"2023-05-18T01:43:51.956117Z","shell.execute_reply.started":"2023-05-18T01:43:51.942221Z","shell.execute_reply":"2023-05-18T01:43:51.954710Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"list_of_adj = generate_networks(10000, 16, 1, 10, 0.2)\nprint(len(list_of_adj))","metadata":{"execution":{"iopub.status.busy":"2023-05-18T01:43:51.959992Z","iopub.execute_input":"2023-05-18T01:43:51.960530Z","iopub.status.idle":"2023-05-18T01:44:02.464260Z","shell.execute_reply.started":"2023-05-18T01:43:51.960487Z","shell.execute_reply":"2023-05-18T01:44:02.462763Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"10000\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Conformément à la documentation du CLRS: https://github.com/deepmind/clrs, pour l'entraînement, 1000 réseaux composés de 16 noeuds seront utilisés. En guise de test, 10000 seront utilisés.","metadata":{}},{"cell_type":"code","source":"print(type(list_of_adj[0]))\nprint(list_of_adj[0])","metadata":{"execution":{"iopub.status.busy":"2023-05-18T01:44:02.466157Z","iopub.execute_input":"2023-05-18T01:44:02.466698Z","iopub.status.idle":"2023-05-18T01:44:02.475629Z","shell.execute_reply.started":"2023-05-18T01:44:02.466628Z","shell.execute_reply":"2023-05-18T01:44:02.474501Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"<class 'numpy.ndarray'>\n[[ 0  0  7  0  0  0  0  0 10  0 10  0  0  9  6  0]\n [ 0  0  0  0  0  5  0  0  0  4  0  0  6  4  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  5  0  0  7]\n [ 0  3  0  0  0  0  0  0  0  0  0  0  5  0  8  0]\n [ 0  0  0  0  0  0  0  0  6  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  1]\n [ 8  0  0  0 10  0  0  0  0  0  0 10  0  0  0  0]\n [ 0  2  0  0  0  0  0  0  0  2  0  0  0  0  0  9]\n [ 0  0  0  0  4  0  9  0  0  0  0  0  5  0  0  3]\n [ 0  6  0  0  2  0  0  0  0  0  0  0  0  0  0  0]\n [ 0  0  0  0  4  0  0  0  0  0  0  6  0  0  0  0]\n [ 5  0  0  0  3  0  0  0  0  0  8  0  9  0  0  0]\n [ 0  0  0  5  0  0  0  0 10  0  0  0  0  0  0  0]\n [ 0  0  9  0  0  0  0  0  1  0  0  0  9  0  0  0]\n [ 0  0  0  0  0  0  0  0  5  0  0  0  0  0  0  2]\n [ 0  0  0  3  0  5  2  0  0  0  2  0  0  0  0  0]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Chaque réseau sera représenté par une matrice d'adjacence et une liste d'incidence pour chaque sommet.","metadata":{}},{"cell_type":"code","source":"def adjacencyToIncidenceList(A):\n    \"\"\"\n    takes an adjacency matrix\n    returns a dict representing the incidence list of each vertex\n    \"\"\"\n    Incidence_list = dict()\n    tp_list = []\n    for v in range(A.shape[0]):\n        Incidence_list[v] = []\n    \n    for v in range(A.shape[0]):\n        w_s = np.argwhere(A[v,:]>0)\n        for w in w_s:\n            if (v,w[0]) not in Incidence_list[v]:\n                Incidence_list[v].append((v,w[0]))\n            if (w[0],v) not in Incidence_list[w[0]]:\n                Incidence_list[w[0]].append((w[0],v))\n        #Incidence_list[v] = [tp_list,-1]# -1 for current edge data structure\n        #tp_list = []\n    return Incidence_list","metadata":{"execution":{"iopub.status.busy":"2023-05-18T01:44:02.476917Z","iopub.execute_input":"2023-05-18T01:44:02.478575Z","iopub.status.idle":"2023-05-18T01:44:02.492922Z","shell.execute_reply.started":"2023-05-18T01:44:02.478485Z","shell.execute_reply":"2023-05-18T01:44:02.491742Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Google OR-Tools a besoin en entrée de la liste des sommets émetteurs, de la liste des sommets récepteurs, et de la liste des capacités pour chaque arc ainsi formé.","metadata":{}},{"cell_type":"code","source":"def adjacencyToListORTools(A):\n    \"\"\"\n    takes an adjacency matrix\n    returns three list of start node, end node and capacities\n    \"\"\"\n    start_node = []\n    end_node = []\n    capacities = []\n    tp_list = []\n    #for v in range(A.shape[0]):\n        #Incidence_list[v] = []\n    \n    for v in range(A.shape[0]):\n        w_s = np.argwhere(A[v,:]>0)\n        for w in w_s:\n            start_node.append(v)\n            end_node.append(w[0])\n            capacities.append(A[v,w[0]])\n        #Incidence_list[v] = [tp_list,-1]# -1 for current edge data structure\n        #tp_list = []\n    return start_node,end_node,capacities","metadata":{"execution":{"iopub.status.busy":"2023-05-18T01:44:02.494257Z","iopub.execute_input":"2023-05-18T01:44:02.495182Z","iopub.status.idle":"2023-05-18T01:44:02.510603Z","shell.execute_reply.started":"2023-05-18T01:44:02.495127Z","shell.execute_reply":"2023-05-18T01:44:02.509089Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def googleORToolsMaxflow(A, s, t):\n    \"\"\"\n    A capacity matrix\n    returns maxflow and s-t cut\n    \"\"\"\n    smf = max_flow.SimpleMaxFlow()\n    start_nodes,end_nodes,capacities = adjacencyToListORTools(A)\n    all_arcs = smf.add_arcs_with_capacity(start_nodes, end_nodes, capacities)\n    # Find the maximum flow between node 0 and node 7.\n    status = smf.solve(s, t)\n    if status != smf.OPTIMAL:\n        print('There was an issue with the max flow input.')\n        print(f'Status: {status}')\n        exit(1)\n    maxflow = smf.optimal_flow()\n    #print('Max flow:', maxflow)\n    #print('')\n    #print(' Arc    Flow / Capacity')\n    #solution_flows = smf.flows(all_arcs)\n    #for arc, flow, capacity in zip(all_arcs, solution_flows, capacities):\n    #print(f'{smf.tail(arc)} / {smf.head(arc)}   {flow:3}  / {capacity:3}')\n    S = smf.get_source_side_min_cut()\n    T = smf.get_sink_side_min_cut()\n    S.sort()\n    T.sort()\n    #print('Source side min-cut:', S)\n    #print('Sink side min-cut:', T)\n    return maxflow,S,T\n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-18T01:44:02.512687Z","iopub.execute_input":"2023-05-18T01:44:02.513989Z","iopub.status.idle":"2023-05-18T01:44:02.532396Z","shell.execute_reply.started":"2023-05-18T01:44:02.513928Z","shell.execute_reply":"2023-05-18T01:44:02.531020Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"#### Implémentation personnelle de l'algorithme Push-Relabel (variante de l'étiquette la plus élevée)","metadata":{}},{"cell_type":"code","source":"def push(v, w, f, r_f, e):\n    \"\"\"\n    v,w: edge through which we will push some flow\n    f: preflow (np 2D array)\n    r_f: residual capacity (np 2D array)\n    e: excess vector (np array)\n    returns f,r_f,e\n    \"\"\"\n    f = f.copy()\n    r_f = r_f.copy()\n    e = e.copy()\n    delta = min(e[v], r_f[v,w])\n    f[v,w] += delta\n    f[w,v] -= delta\n    r_f[v,w] -= delta\n    r_f[w,v] += delta\n    e[v] -= delta\n    e[w] += delta\n    return f,r_f,e\n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-18T01:44:02.533897Z","iopub.execute_input":"2023-05-18T01:44:02.535008Z","iopub.status.idle":"2023-05-18T01:44:02.549695Z","shell.execute_reply.started":"2023-05-18T01:44:02.534962Z","shell.execute_reply":"2023-05-18T01:44:02.548031Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def relabel(v, r_f, d):\n    \"\"\"\n    relabelling operation\n    v: vertex\n    r_f: residual capacity (np 2D array)\n    d: label\n    returns d\n    \"\"\"\n    w_s = np.argwhere(r_f[v,:]> 1e-6)\n    d = d#.copy()\n    if len(w_s) > 0:\n        mini = np.min(d[w_s])\n        #print(mini)\n        d[v] = mini + 1\n    return d","metadata":{"execution":{"iopub.status.busy":"2023-05-18T01:44:02.551732Z","iopub.execute_input":"2023-05-18T01:44:02.552149Z","iopub.status.idle":"2023-05-18T01:44:02.571734Z","shell.execute_reply.started":"2023-05-18T01:44:02.552100Z","shell.execute_reply":"2023-05-18T01:44:02.570210Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def procedure(A, C, Q, v, s, t, f, r_f, e, d, current_edge, rel):\n    \"\"\"\n    A: dict of the incidence lists of each vertex, with G being a symmetric digraph\n    C: capacity matrix\n    Q: priority queue\n    v: removed vertex with highest label priority in Q\n    s: source node\n    t: sink node\n    f: preflow\n    r_f: residual capacity\n    e: excess vector\n    d: label vector\n    rel: a boolean variable associated with the highest label push algorithm\n    \n    returns f, r_f, e, d, rel\n    \"\"\"\n    A = A.copy()\n    Q = Q.copy()\n    f = f.copy()\n    r_f = r_f.copy()\n    e = e.copy()\n    d = d.copy()\n    current_edge = current_edge.copy()\n    rel = rel\n    # Current edge in A_v\n    v,w = A[v][current_edge[v]]\n    #print(v,w)\n\n    inside_queue = False\n    # Adding for underflow \n    if(C[v,w] - f[v,w] > 1e-6 and (d[v]==d[w]+1)):\n\n        #print(\"e before\", e)\n        f, r_f, e = push(v, w, f, r_f, e)\n        #print(\"e after\", e)\n\n        for priority,vertex in Q:\n            if(w==vertex):\n                inside_queue = True\n        if((not inside_queue) and w != s and w != t):\n\n            Q.append((-d[w],w))\n            Q.sort(key=lambda vertex: vertex[0])#sort by priority\n\n    elif e[v] > 1e-6:\n\n        if current_edge[v] < len(A[v])-1:\n\n            current_edge[v] = current_edge[v] + 1 \n\n        else:\n\n            d = relabel(v, r_f, d)\n            #print(d)\n            rel = True\n            # first edge as current edge\n            current_edge[v] = 0\n\n    return A,Q,f,r_f,e,d,current_edge,rel","metadata":{"execution":{"iopub.status.busy":"2023-05-18T01:44:02.573771Z","iopub.execute_input":"2023-05-18T01:44:02.575003Z","iopub.status.idle":"2023-05-18T01:44:02.592599Z","shell.execute_reply.started":"2023-05-18T01:44:02.574944Z","shell.execute_reply":"2023-05-18T01:44:02.591218Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def HLFlow(A, C, s, t):\n    \"\"\"\n    Highest Label flow push algorithm, Goldberg and Tarjan 1988\n    A: Incidence lists\n    C: capacity matrix\n    s: source node\n    t: sink node\n    return flow_value\n    \"\"\"\n    # Initialization of all variables\n    #preflow\n    n,m = C.shape\n    f = np.full((n,m), 0.)\n    for v in range(n):\n        f[s,v] = C[s,v]\n        f[v,s] = -C[s,v]\n    # labels and excess\n    d = np.array([0 for i in range(n)])\n    e = np.array([0.0 for i in range(n)])\n    d[s] = n\n    for v in range(n):\n        if v!= s:\n            e[v] = f[s,v]\n            \n    # residual capacity\n    r_f = C - f\n    for v in range(n):\n        if v != s:\n            r_f[s,v] = 0.\n            r_f[v,s] = C[v,s] + C[s,v]\n    # priority queue and current edge for each A_v\n    Q = []\n    current_edge = np.array([0 for i in range(n)])\n    for v in range(n):\n        if v!= s:\n            # make the first edge the current edge\n            current_edge[v] = 0\n            # pushing in Q\n            if e[v] > 0 and v != t:\n                Q.append((-d[v],v))\n    Q.sort(key=lambda vertex: vertex[0])# sort by priority\n    while len(Q) > 0:\n        # remove vertex of highest priority\n        priority,v = Q.pop(0)\n        rel = False\n        A,Q,f,r_f,e,d,current_edge,rel = procedure(A, C, Q, v, s, t, f, r_f, e, d, current_edge,rel)\n        while(e[v] > 0. and rel==False):\n            A,Q,f,r_f,e,d,current_edge,rel = procedure(A, C, Q, v, s, t, f, r_f, e, d, current_edge, rel)\n        #if e[v] > 0 and d[v] < n and -d[v] < priority:\n        if e[v] > 0 :\n            Q.append((-d[v],v))\n            Q.sort(key=lambda vertex: vertex[0])# sort by priority\n            \n    S = []\n    T = []\n    target_height = -1\n    for height in range(1,n):\n        if height not in d:\n            target_height = height\n            #break\n    if target_height != -1:\n        for vertex in np.argwhere(d > target_height):\n            S.append(vertex[0])\n        \n        for vertex in np.argwhere(d < target_height):\n            T.append(vertex[0])\n    else:\n        S = []\n        T = []\n    return e[t],S,T","metadata":{"execution":{"iopub.status.busy":"2023-05-18T01:44:02.594050Z","iopub.execute_input":"2023-05-18T01:44:02.594529Z","iopub.status.idle":"2023-05-18T01:44:02.621823Z","shell.execute_reply.started":"2023-05-18T01:44:02.594405Z","shell.execute_reply":"2023-05-18T01:44:02.620602Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"#### Petits tests","metadata":{}},{"cell_type":"code","source":"C1 = np.array(\n    [\n    [0,13,15,0],\n    [0,0,7,12],\n    [0,8,0,20],\n    [0,0,0,0]\n    ]\n    )\n\nA2 = adjacencyToIncidenceList(C1)\nprint(A2)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T01:44:02.628379Z","iopub.execute_input":"2023-05-18T01:44:02.629519Z","iopub.status.idle":"2023-05-18T01:44:02.643635Z","shell.execute_reply.started":"2023-05-18T01:44:02.629469Z","shell.execute_reply":"2023-05-18T01:44:02.642168Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"{0: [(0, 1), (0, 2)], 1: [(1, 0), (1, 2), (1, 3)], 2: [(2, 0), (2, 1), (2, 3)], 3: [(3, 1), (3, 2)]}\n","output_type":"stream"}]},{"cell_type":"code","source":"C2 = np.array(\n    [\n    [0,38,1,2,0,0,0,0],\n    [0,0,8,0,13,0,10,0],\n    [0,0,0,0,0,0,26,0],\n    [0,0,0,0,0,0,0,27],\n    [0,0,2,0,0,1,0,7],\n    [0,0,0,0,0,0,0,7],\n    [0,0,0,24,0,8,0,1],\n    [0,0,0,0,0,0,0,0]\n    ]\n    )\n\nA3 = adjacencyToIncidenceList(C2)\nprint(A3)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T01:44:02.645385Z","iopub.execute_input":"2023-05-18T01:44:02.646044Z","iopub.status.idle":"2023-05-18T01:44:02.662932Z","shell.execute_reply.started":"2023-05-18T01:44:02.646005Z","shell.execute_reply":"2023-05-18T01:44:02.661603Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"{0: [(0, 1), (0, 2), (0, 3)], 1: [(1, 0), (1, 2), (1, 4), (1, 6)], 2: [(2, 0), (2, 1), (2, 6), (2, 4)], 3: [(3, 0), (3, 7), (3, 6)], 4: [(4, 1), (4, 2), (4, 5), (4, 7)], 5: [(5, 4), (5, 7), (5, 6)], 6: [(6, 1), (6, 2), (6, 3), (6, 5), (6, 7)], 7: [(7, 3), (7, 4), (7, 5), (7, 6)]}\n","output_type":"stream"}]},{"cell_type":"code","source":"flow_value4 = HLFlow(A3, C2, 0, 7)\nprint(flow_value4)\nflow_value4 = googleORToolsMaxflow(C2, 0, 7)\nprint(flow_value4)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T01:44:02.664830Z","iopub.execute_input":"2023-05-18T01:44:02.665293Z","iopub.status.idle":"2023-05-18T01:44:02.698669Z","shell.execute_reply.started":"2023-05-18T01:44:02.665254Z","shell.execute_reply":"2023-05-18T01:44:02.697406Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"(31.0, [0, 1, 4], [2, 3, 5, 6, 7])\n(31, [0, 1, 4], [2, 3, 5, 6, 7])\n","output_type":"stream"}]},{"cell_type":"code","source":"flow_value1 = HLFlow(A2, C1, 0, 3)\ngoogleORToolsMaxflow(C1, 0, 3)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T01:44:02.700359Z","iopub.execute_input":"2023-05-18T01:44:02.701647Z","iopub.status.idle":"2023-05-18T01:44:02.715476Z","shell.execute_reply.started":"2023-05-18T01:44:02.701591Z","shell.execute_reply":"2023-05-18T01:44:02.713984Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"(28, [0], [1, 2, 3])"},"metadata":{}}]},{"cell_type":"code","source":"print(flow_value1)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T01:44:02.717363Z","iopub.execute_input":"2023-05-18T01:44:02.718255Z","iopub.status.idle":"2023-05-18T01:44:02.725346Z","shell.execute_reply.started":"2023-05-18T01:44:02.718200Z","shell.execute_reply":"2023-05-18T01:44:02.723716Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"(28.0, [0], [1, 2, 3])\n","output_type":"stream"}]},{"cell_type":"code","source":"A = adjacencyToIncidenceList(list_of_adj[1])\nflow_value = HLFlow(A, list_of_adj[1], 0, list_of_adj[1].shape[0]-1)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T01:44:02.726838Z","iopub.execute_input":"2023-05-18T01:44:02.727278Z","iopub.status.idle":"2023-05-18T01:44:02.744992Z","shell.execute_reply.started":"2023-05-18T01:44:02.727237Z","shell.execute_reply":"2023-05-18T01:44:02.743975Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"print(flow_value)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T01:44:02.746750Z","iopub.execute_input":"2023-05-18T01:44:02.747485Z","iopub.status.idle":"2023-05-18T01:44:02.756728Z","shell.execute_reply.started":"2023-05-18T01:44:02.747442Z","shell.execute_reply":"2023-05-18T01:44:02.755564Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"(3.0, [0, 11, 14], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 15])\n","output_type":"stream"}]},{"cell_type":"code","source":"googleORToolsMaxflow(list_of_adj[1], 0, list_of_adj[1].shape[0]-1)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T01:44:02.758089Z","iopub.execute_input":"2023-05-18T01:44:02.758690Z","iopub.status.idle":"2023-05-18T01:44:02.777728Z","shell.execute_reply.started":"2023-05-18T01:44:02.758638Z","shell.execute_reply":"2023-05-18T01:44:02.776227Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"(3, [0, 11, 14], [1, 2, 3, 4, 5, 7, 9, 10, 12, 13, 15])"},"metadata":{}}]},{"cell_type":"code","source":"G=nx.from_numpy_matrix(list_of_adj[4])\nfvalue = nx.maximum_flow_value(G,0,list_of_adj[4].shape[0]-1,capacity='weight')","metadata":{"execution":{"iopub.status.busy":"2023-05-18T01:44:02.779582Z","iopub.execute_input":"2023-05-18T01:44:02.779936Z","iopub.status.idle":"2023-05-18T01:44:02.790742Z","shell.execute_reply.started":"2023-05-18T01:44:02.779902Z","shell.execute_reply":"2023-05-18T01:44:02.789324Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"G1=nx.from_numpy_matrix(C2)\nfvalue1 = nx.minimum_cut(G1,0,C2.shape[0]-1,capacity='weight',flow_func=nx.algorithms.flow.preflow_push)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T01:44:02.792371Z","iopub.execute_input":"2023-05-18T01:44:02.793394Z","iopub.status.idle":"2023-05-18T01:44:02.808103Z","shell.execute_reply.started":"2023-05-18T01:44:02.793351Z","shell.execute_reply":"2023-05-18T01:44:02.806661Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"print(fvalue1)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T01:44:02.810005Z","iopub.execute_input":"2023-05-18T01:44:02.810527Z","iopub.status.idle":"2023-05-18T01:44:02.828197Z","shell.execute_reply.started":"2023-05-18T01:44:02.810475Z","shell.execute_reply":"2023-05-18T01:44:02.826732Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"(31, ({0, 1, 4}, {2, 3, 5, 6, 7}))\n","output_type":"stream"}]},{"cell_type":"code","source":"flow_value4 = HLFlow(A3, C2, 0, 7)\nprint(flow_value4)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T01:44:02.829343Z","iopub.execute_input":"2023-05-18T01:44:02.829726Z","iopub.status.idle":"2023-05-18T01:44:02.847441Z","shell.execute_reply.started":"2023-05-18T01:44:02.829689Z","shell.execute_reply":"2023-05-18T01:44:02.846446Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"(31.0, [0, 1, 4], [2, 3, 5, 6, 7])\n","output_type":"stream"}]},{"cell_type":"code","source":"print(fvalue)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T01:44:02.848770Z","iopub.execute_input":"2023-05-18T01:44:02.849161Z","iopub.status.idle":"2023-05-18T01:44:02.861814Z","shell.execute_reply.started":"2023-05-18T01:44:02.849104Z","shell.execute_reply":"2023-05-18T01:44:02.860366Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"32\n","output_type":"stream"}]},{"cell_type":"code","source":"print(list_of_adj[4])","metadata":{"execution":{"iopub.status.busy":"2023-05-18T01:44:02.863908Z","iopub.execute_input":"2023-05-18T01:44:02.864403Z","iopub.status.idle":"2023-05-18T01:44:02.880082Z","shell.execute_reply.started":"2023-05-18T01:44:02.864353Z","shell.execute_reply":"2023-05-18T01:44:02.878802Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"[[ 0  0  0  0  0  0  8  0  0  4  0  6  0  0  0  0]\n [10  0  0  0  0  0  0  0  0  0  0  0  0  8  0  0]\n [ 0  0  0  8  5  0  7  0  0  9  0  0  0  9  0  0]\n [ 0  0  0  0  7  0  3  4  0  0  0  0  0  0  0 10]\n [ 0  0  0  0  0  0  0  3  0  0  0  0  0  5  0  0]\n [ 1  0  0  0  0  0  0  0  0  0  0  8  0  0  0  0]\n [ 0  0  0  6  0  0  0  0  0  0  9  0  0  2  0  0]\n [ 0  0  9  0  0  2  0  0  0  0  0  5  2  0  3  5]\n [ 0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  9  0  3  0  0  0  0  0  7  0  0]\n [ 0  0  0  2  0  0  4  0  0  0  0  0  0  0  0  8]\n [ 0  6  0  0  0  0  0  0  0  0  0  0  1  0  0  0]\n [ 0  0  0  0  0  0  7  1  0  0  0  0  0  0  7  0]\n [ 9  0  0  0  6  0  0  0  0  4  0  0  7  0  0  0]\n [ 0  0  2  0  6  0  0  0  0  0  0  0  0  0  0  0]\n [ 4  1  0  0  0  0  6  0  0  0  0  0  0  0  0  0]]\n","output_type":"stream"}]},{"cell_type":"code","source":"A3 = adjacencyToIncidenceList(list_of_adj[4])\nflow_value2 = HLFlow(A3, list_of_adj[4], 0, list_of_adj[4].shape[0]-1)\nprint(flow_value2)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T01:44:02.881904Z","iopub.execute_input":"2023-05-18T01:44:02.882300Z","iopub.status.idle":"2023-05-18T01:44:02.900791Z","shell.execute_reply.started":"2023-05-18T01:44:02.882263Z","shell.execute_reply":"2023-05-18T01:44:02.899707Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"(18.0, [0], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15])\n","output_type":"stream"}]},{"cell_type":"code","source":"G=nx.from_numpy_matrix(list_of_adj[4])\nfvalue = nx.minimum_cut(G,0,list_of_adj[4].shape[0]-1,capacity='weight',flow_func=nx.algorithms.flow.preflow_push)\nprint(fvalue)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T01:44:02.902506Z","iopub.execute_input":"2023-05-18T01:44:02.902866Z","iopub.status.idle":"2023-05-18T01:44:02.915378Z","shell.execute_reply.started":"2023-05-18T01:44:02.902833Z","shell.execute_reply":"2023-05-18T01:44:02.913833Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"(32, ({0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14}, {10, 15}))\n","output_type":"stream"}]},{"cell_type":"code","source":"googleORToolsMaxflow(list_of_adj[4], 0, list_of_adj[4].shape[0]-1)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T01:44:02.916712Z","iopub.execute_input":"2023-05-18T01:44:02.917053Z","iopub.status.idle":"2023-05-18T01:44:02.935219Z","shell.execute_reply.started":"2023-05-18T01:44:02.917019Z","shell.execute_reply":"2023-05-18T01:44:02.934014Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"(18, [0], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15])"},"metadata":{}}]},{"cell_type":"markdown","source":"### Tests face à Google OR-Tools sur les 1000 réseaux générés","metadata":{}},{"cell_type":"code","source":"def computeCut(C,S,T):\n    cut = 0.\n    for u in S:\n        for v in T:\n            cut += C[u,v]\n    return cut","metadata":{"execution":{"iopub.status.busy":"2023-05-18T01:44:02.937684Z","iopub.execute_input":"2023-05-18T01:44:02.938079Z","iopub.status.idle":"2023-05-18T01:44:02.951914Z","shell.execute_reply.started":"2023-05-18T01:44:02.938041Z","shell.execute_reply":"2023-05-18T01:44:02.950764Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def test_HLFlowVsGoogleOR(list_of_adjacency):\n    counter_diff_cut = 0\n    counter_diff_flow_value = 0\n    diff_cut = 0\n    print(\"testing \" + str(len(list_of_adjacency)) + \" networks\")\n    for adjacency_matrix in list_of_adjacency:\n        A = adjacencyToIncidenceList(adjacency_matrix)\n        s = random.randrange(adjacency_matrix.shape[0])\n        t = random.randrange(adjacency_matrix.shape[0])\n        while s==t:\n            t = random.randrange(adjacency_matrix.shape[0])\n        flow_value = HLFlow(A, adjacency_matrix, s, t)\n        flow_value1 = googleORToolsMaxflow(adjacency_matrix, s, t)\n        \n        if(flow_value[1] != flow_value1[1]):\n            print(flow_value[1])\n            print(flow_value1[1])\n            print(\"cut HLFLOW\",flow_value[2])\n            print(\"cut OR Tools\",flow_value1[2])\n            print(flow_value1[0] == flow_value[0])\n            print(flow_value1[0])\n            counter_diff_cut += 1\n            cut = computeCut(adjacency_matrix,flow_value[1],flow_value[2])\n            cut1 = computeCut(adjacency_matrix,flow_value1[1],flow_value1[2])\n            if cut != cut1:\n                diff_cut += 1\n                print(cut,cut1)\n            if flow_value[0] != flow_value1[0]:\n                counter_diff_flow_value += 1\n    print(\"diff cut\", counter_diff_cut)\n    print(\"diff flow\",counter_diff_flow_value)\n    print(\"diff cut value\",diff_cut)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T01:44:02.953651Z","iopub.execute_input":"2023-05-18T01:44:02.954154Z","iopub.status.idle":"2023-05-18T01:44:02.971298Z","shell.execute_reply.started":"2023-05-18T01:44:02.954086Z","shell.execute_reply":"2023-05-18T01:44:02.969784Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"test_HLFlowVsGoogleOR(list_of_adj)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T01:44:02.973288Z","iopub.execute_input":"2023-05-18T01:44:02.973783Z","iopub.status.idle":"2023-05-18T01:46:08.578490Z","shell.execute_reply.started":"2023-05-18T01:44:02.973742Z","shell.execute_reply":"2023-05-18T01:46:08.576923Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"testing 10000 networks\n[15]\n[]\ncut HLFLOW [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\ncut OR Tools []\nTrue\n0\n[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 12, 13, 14]\n[]\ncut HLFLOW [6, 11, 15]\ncut OR Tools []\nTrue\n0\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n[]\ncut HLFLOW [15]\ncut OR Tools []\nTrue\n0\ndiff cut 3\ndiff flow 0\ndiff cut value 0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Nous voyons ici que sur les 10000 réseaux, il n'y a eu que 3 réseaux où la coupe donnée par l'implémentation personnelle de l'algorithme de Goldberg Tarjan et celle de Google OR-Tools a différé (indiqué par **diff cut**). Cependant, aucune différence en terme de valeur du flot maximum, ni de différence pour la capacité de la coupe minimum n'a été trouvé. ","metadata":{}},{"cell_type":"markdown","source":"### ***Étapes suivantes***\n#### 1. Adaptation de l'implémentation aux exigences du CLRS-30:\nLe CLRS ne prend en charge que 5 types de structures de données:\n* scalaire: nombre réels\n* catégorielle: indiquant l'appartenance ou non à K différentes catégories\n* mask: indiquant l'appartenance ou non à deux catégories (1 ou 0)\n* mask_one: indiquant l'appartenance ou non à deux catégories (1 ou 0) où un seul sommet est actif\n* pointeur\n\nChaque variable de l'algorithme devra être de l'un de ces types, il faudra également spécifié si la variable est une variable d'entrée, de sortie ou une variable indiquant l'état interne de l'algorithme.\n\nEn guise d'exemple, soient C, la matrice d'adjacence et de capacité d'un réseau, s, le sommet source, et t, le sommet puit.\nC sera une variable d'entrée dans la catégorie scalaire car les capacités sont des nombres réels, s sera représenté comme suit:\nReprésentons les sommets en tant que vecteur, les sommets seront numérotés de 0 à n-1, pour n sommets.\nla représentation de s sera:\n\nsommets: 0 1 2 3 4 5 6 7 ... s ... n-1      \nétat: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;0 0 0 0 0 0 0 0 ... 1 ... 0\n\nt sera représenté de même. Ainsi, s et t sont dans la catégorie mask_one.\n\n#### 2. Collecte des données d'entraînements\nUne fois les variables dans le format correct, il faudra enregistrer l'évolution de chaque variable au cours de l'execution de l'algorithme, formant ainsi une trajectoire pour chaque variable.\n\n#### 3. Entraînement des réseaux de neurones\nLe CLRS fournit six architectures de réseaux de neurones, une fois les données acquises, elle seront fournis au module de génération de données d'entraînement du CLRS puis seront passées aux modèles pour la phase d'entraînement.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}